{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"/Users/reem/Desktop/Langchain_tutorials/covered_topics.pdf\"),\n",
    "    PyPDFLoader(\"/Users/reem/Desktop/Langchain_tutorials/llm.pdf\"),\n",
    "    # PyPDFLoader(\"/Users/reem/Desktop/Langchain_tutorials/covered topics.pdf\")\n",
    "    # PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture02.pdf\"),\n",
    "    # PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wp/g4_x_xzn5dj59z7qh4r7bmr40000gn/T/ipykernel_2850/2897838732.py:1: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings()\n",
      "/var/folders/wp/g4_x_xzn5dj59z7qh4r7bmr40000gn/T/ipykernel_2850/2897838732.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(\n"
     ]
    }
   ],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldb = Chroma.from_texts(texts, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(metadata={}, page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.similarity_search(question, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(metadata={}, page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MMR  IT CAPTURES DIVERSITY\n",
    "smalldb.max_marginal_relevance_search(question,k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "q= \"what are the projects? \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covered Topics \n",
      "• OpenCV Multimedia Processing: \n",
      "- Image Filtering Basics \n",
      "- Morphological Image processing \n",
      "- BITWISWE  \n",
      "- Transformation Functions \n",
      "- Feature Extraction \n",
      "- Operations \n",
      "- Blurring Techniques \n",
      "- Color Spaces \n",
      "- Contour Detection \n",
      "- Edge Detection \n",
      "- Masking \n",
      "- Threshold Techniques \n",
      "- Face Detection Using haar cascade \n",
      "Reference: \n",
      "https://drive.google.com/file/d/14BsnVqC2c6NNsV4MrAg79ltP_h6Fzd5e/vi\n",
      "ew?usp=share_link \n",
      " \n",
      "• Object Detection And Tracking With Ultralytics YOLO: \n",
      "- Model’s Versions And Capabilities Exploration \n",
      "- Bounding Boxes Basics(IOU, mAP, Nms, Confidence Threshold) \n",
      "- Understanding Model’s Functionalities\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \n",
      "Courses \n",
      "• Neural Networks And Deep learning with Andrew Ng \n",
      "• Prompt Engineering With Llama 2&3\n"
     ]
    }
   ],
   "source": [
    "print(docs[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are projects in the third document?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': 'Reem Alamoudi', 'creationdate': '2025-02-26T10:46:13+00:00', 'creator': 'Microsoft Word', 'moddate': '2025-02-26T10:46:13+00:00', 'page': 3, 'page_label': '4', 'producer': 'PyPDF', 'source': '/Users/reem/Desktop/Langchain_tutorials/covered topics.pdf', 'total_pages': 6}\n",
      "{'author': 'Reem Alamoudi', 'creationdate': '2025-02-26T10:46:13+00:00', 'creator': 'Microsoft Word', 'moddate': '2025-02-26T10:46:13+00:00', 'page': 4, 'page_label': '5', 'producer': 'PyPDF', 'source': '/Users/reem/Desktop/Langchain_tutorials/covered topics.pdf', 'total_pages': 6}\n",
      "{'author': '', 'creationdate': '2025-01-16T20:13:48-05:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-01-16T20:13:48-05:00', 'page': 117, 'page_label': '111', 'producer': 'GPL Ghostscript 10.01.2', 'source': '/Users/reem/Desktop/Langchain_tutorials/llm.pdf', 'subject': '', 'title': '', 'total_pages': 231}\n",
      "{'author': '', 'creationdate': '2025-01-16T20:13:48-05:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-01-16T20:13:48-05:00', 'page': 119, 'page_label': '113', 'producer': 'GPL Ghostscript 10.01.2', 'source': '/Users/reem/Desktop/Langchain_tutorials/llm.pdf', 'subject': '', 'title': '', 'total_pages': 231}\n",
      "{'author': 'Reem Alamoudi', 'creationdate': '2025-02-26T10:46:13+00:00', 'creator': 'Microsoft Word', 'moddate': '2025-02-26T10:46:13+00:00', 'page': 2, 'page_label': '3', 'producer': 'PyPDF', 'source': '/Users/reem/Desktop/Langchain_tutorials/covered topics.pdf', 'total_pages': 6}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata)          #it got it from not only the specifies document but other docs as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 \n",
      "Courses \n",
      "• Neural Networks And Deep learning with Andrew Ng \n",
      "• Prompt Engineering With Llama 2&3\n"
     ]
    }
   ],
   "source": [
    "print(docs[4].page_content) #it is not picking up that we only want info from the third doc  , we can either add a filter or use SelfQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually specifiying :\n",
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\":\"docs/cs229_lectures/MachineLearning-Lecture03.pdf\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelfQuery\n",
    "\n",
    "### Addressing Specificity: working with metadata using self-query retriever\n",
    "\n",
    "But we have an interesting challenge: we often want to infer the metadata from the query itself.\n",
    "\n",
    "To address this, we can use `SelfQueryRetriever`, which uses an LLM to extract:\n",
    " \n",
    "1. The `query` string to use for vector search\n",
    "2. A metadata filter to pass in as well\n",
    "\n",
    "Most vector databases support metadata filters, so this doesn't require any new databases or indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo   #where we can specify different fields in the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be pased to the language model, so it is important to nake it as descriptive as possible\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture the chunk is from, should be one of `/Users/reem/Desktop/Langchain_tutorials/covered topics.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wp/g4_x_xzn5dj59z7qh4r7bmr40000gn/T/ipykernel_2850/90427950.py:3: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n"
     ]
    }
   ],
   "source": [
    "import lark\n",
    "document_content_description = \"Covered topics\"\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are projects in the  document?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': '', 'creationdate': '2025-01-16T20:13:48-05:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-01-16T20:13:48-05:00', 'page': 1, 'page_label': 'i', 'producer': 'GPL Ghostscript 10.01.2', 'source': '/Users/reem/Desktop/Langchain_tutorials/llm.pdf', 'subject': '', 'title': '', 'total_pages': 231}\n",
      "{'author': '', 'creationdate': '2025-01-16T20:13:48-05:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-01-16T20:13:48-05:00', 'page': 126, 'page_label': '120', 'producer': 'GPL Ghostscript 10.01.2', 'source': '/Users/reem/Desktop/Langchain_tutorials/llm.pdf', 'subject': '', 'title': '', 'total_pages': 231}\n",
      "{'author': '', 'creationdate': '2025-01-16T20:13:48-05:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-01-16T20:13:48-05:00', 'page': 117, 'page_label': '111', 'producer': 'GPL Ghostscript 10.01.2', 'source': '/Users/reem/Desktop/Langchain_tutorials/llm.pdf', 'subject': '', 'title': '', 'total_pages': 231}\n",
      "{'author': '', 'creationdate': '2025-01-16T20:13:48-05:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2025-01-16T20:13:48-05:00', 'page': 137, 'page_label': '131', 'producer': 'GPL Ghostscript 10.01.2', 'source': '/Users/reem/Desktop/Langchain_tutorials/llm.pdf', 'subject': '', 'title': '', 'total_pages': 231}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional tricks: compression\n",
    "\n",
    "Another approach for improving the quality of retrieved docs is compression.\n",
    "\n",
    "Information most relevant to a query may be buried in a document with a lot of irrelevant text. \n",
    "\n",
    "Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
    "\n",
    "Contextual compression is meant to fix this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap our vectorstore\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "- Defining Project Pipeline And Requirements \n",
      "- Custom Dataset Processing (Collection, Labelling, Annotation) \n",
      "- Fine Tuning Pre-Trained Model (YOLOv11) \n",
      "- Testing The Model Then Deploying it\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "T axi Driver: Deﬁnitely check out the botanical gardens after the museum.\n",
      "They’re nearby and quite beautiful.\n",
      "T ourist: Great, thanks for the tip!\n",
      "T axi Driver: No problem. Enjoy your visit!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Another application of text completion is generating text b ased on user requirements. The\n",
      "requirements can include style, tone, length, and any speci ﬁc content that the text should contain.\n",
      "For example, users may need a formal report, a creative story , or a piece of programming code.\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about projects?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "- Defining Project Pipeline And Requirements \n",
      "- Custom Dataset Processing (Collection, Labelling, Annotation) \n",
      "- Fine Tuning Pre-Trained Model (YOLOv11) \n",
      "- Testing The Model Then Deploying it\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Another application of text completion is generating text b ased on user requirements. The\n",
      "requirements can include style, tone, length, and any speci ﬁc content that the text should contain.\n",
      "For example, users may need a formal report, a creative story , or a piece of programming code.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "involving multiple prompts\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "• Language Modeling . T ypically , this approach refers to an auto-regressive gen eration pro-\n",
      "cedure of sequences. At one time, it predicts the next token b ased on its previous context.\n",
      "• Masked Language Modeling . Masked Language Modeling belongs to a general mask-\n",
      "predict framework. It randomly masks tokens in a sequence an d predicts these tokens using\n",
      "the entire masked sequence.\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about projects?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other types of retrieval\n",
    "\n",
    "It's worth noting that vectordb as not the only kind of tool to retrieve documents. \n",
    "\n",
    "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "loader = PyPDFLoader(\"/Users/reem/Desktop/Langchain_tutorials/covered topics.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "docs_tfidf[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
